---	
- name: Create VPC
  cloudformation:
    stack_name: petclinic-vpc
    state: present
    region: "{{ region }}"
    template: "roles/{{ role_name }}/files/eks-vpc.yaml"
    template_parameters:
      PublicSubnet1AZ: "{{ region }}a"
      PublicSubnet2AZ: "{{ region }}b"
      PrivateSubnet1AZ: "{{ region }}a"
      PrivateSubnet2AZ: "{{ region }}b"
  ignore_errors: true
  register: vpc_stack

  
- name: Get VPC Info
  cloudformation_info:
    stack_name: petclinic-vpc
    region: "{{ region }}"
  register: vpc_stack_info

- name: Set VPC Info
  set_fact:
    vpc_info:  "{{vpc_stack_info.cloudformation['petclinic-vpc'].stack_outputs}}"
    
- name: Create ec2-key pair
  ec2_key:
    name: petclinic
    region: "{{ region }}"
  register: ec2_key_result
  
- name: Save private key
  copy: content="{{ ec2_key_result.key.private_key }}" dest="./petclinic.pem" mode=0600
  when: ec2_key_result.changed
    
- name: Set Vars
  set_fact:
    eksClusterName: petclinic-eks
    region: "{{ region }}"
    a_stack_az: "{{ region }}a"
    b_stack_az: "{{ region }}b"
    a_stack_pub_subnet: "{{ vpc_info.PublicSubnet1Id }}"
    b_stack_pub_subnet: "{{ vpc_info.PublicSubnet2Id }}"
    a_stack_priv_subnet: "{{ vpc_info.PrivateSubnet1Id }}"
    b_stack_priv_subnet: "{{ vpc_info.PrivateSubnet2Id }}"
    vpc_id: "{{ vpc_info.VPCId }}"
    
- name: Generate eks-cluster.yaml
  template:
    src: "roles/{{ role_name }}/files/eks-cluster.yaml"
    dest: /tmp/eks-cluster.yaml

# populate a clusters_exist list with names of clusters TAB "\t"
- name: "Getting existing clusters list"
  command: "aws --region {{ region }} eks list-clusters --query [clusters] --output text"
  register: clusters_exist
  
- debug:
    msg: "{{ clusters_exist.stdout }}"
   
# create a list from clusters_exist
- set_fact:
    found_clusters_list: "{{ clusters_exist.stdout.split('\t') }}"
    
- name: "Settting eksctl action to either Create or Update"
  set_fact:
    eksctl_action: "{{ 'create' if (eksClusterName not in found_clusters_list) else 'update' }}"
    
- name: "Running eksctl eksctl_action {{ eksctl_action | upper }} cluster with name {{ eksClusterName | upper }}"
  command: "eksctl {{ eksctl_action }} cluster -f /tmp/eks-cluster.yaml"
  
- name: Add Kubectl configuration
  shell: "aws eks update-kubeconfig --name {{ eksClusterName }} --region {{ region }}"
  ignore_errors: yes
  
- name: Get OIDC Info - Issuer URL
  shell: "aws eks describe-cluster --name {{ eksClusterName }} --region {{ region }} --query cluster.identity.oidc.issuer --output text"
  register: oidc_issuer_url_output
  
- name: Get OIDC Info - Issuer Host Path
  shell: "echo {{ oidc_issuer_url_output.stdout }} | cut -f 3- -d'/' "
  register: oidc_issuer_host_path_output

- name: Get OIDC Info - AWS Account Id
  shell: "aws sts get-caller-identity --query Account --output text"
  register: aws_account_id_output

- name: Enable OIDC Provider
  shell: "eksctl utils associate-iam-oidc-provider --name {{ eksClusterName }} --region {{ region }} --approve"
  ignore_errors: yes
  
- name: Set OIDC Provider Info
  set_fact:
    oidc_issuer_provider_arn: "arn:aws:iam::{{ aws_account_id_output.stdout }}:oidc-provider/{{ oidc_issuer_host_path_output.stdout }}"
    oidc_issuer_provider_host_path: "{{ oidc_issuer_host_path_output.stdout }}"

- name: Output OIDC Provider Info
  debug:
    msg: "oidc info: {{ oidc_issuer_provider_arn }}, oidc host path: {{ oidc_issuer_provider_host_path }} "
    
- name: Configure CLuster autoScaler
  template:
    src: "roles/{{ role_name }}/templates/cluster-autoscaler.yaml"
    dest: /tmp/cluster-autoscaler.yaml

- name: Install Cluster autoscaler for capacity
  shell: "kubectl apply -f /tmp/cluster-autoscaler.yaml"
  
- name: Create Argo namespace
  shell: "kubectl create namespace argocd"
  
- name: Deploy Argocd pods
  shell: "kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/v2.0.4/manifests/install.yaml"
  
- name: API server interaction
  shell: "sudo curl --silent --location -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/download/v2.0.4/argocd-linux-amd64"
  
- name: chmod argocd
  shell: "sudo chmod +x /usr/local/bin/argocd"

- name: patch argocd server
  shell: "kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'"
  
- name: Pause for 3 minutes to build argo load balancer
  pause:
    minutes: 3
  
- name: export ARGOCD_SERVER
  shell: "export ARGOCD_SERVER=`kubectl get svc argocd-server -n argocd -o json | jq --raw-output '.status.loadBalancer.ingress[0].hostname'`"
  register: ARGOCD_SERVER
  
- name: export 
  shell: "export ARGO_PWD=`kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d`"
  register: ARGO_PWD

- debug:
    msg: "{{ ARGOCD_SERVER.stdout }}"
    
- debug:
    msg: "{{ ARGO_PWD.stdout }}"
